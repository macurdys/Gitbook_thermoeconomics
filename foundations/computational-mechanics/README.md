# Computational Mechanics

James Crutchfield's **computational mechanics** provides a rigorous mathematical framework for understanding the information processing that occurs in natural systems. Where Shannon tells you *how much* information a system produces, Crutchfield tells you *how* that information is structured — what patterns exist, what is predictable, and what is genuinely random.

This is directly relevant to thermoeconomics because proof-of-work mining is a physical information-processing system, and computational mechanics gives us the tools to analyze exactly what it computes.

---

## Key Resources

- [Complexity Sciences Center, UC Davis](https://csc.ucdavis.edu/) — Crutchfield's research group
- Crutchfield, "Between Order and Chaos" (2012) — accessible overview
- Crutchfield & Young, "Inferring Statistical Complexity" (1989) — foundational paper
- Shalizi & Crutchfield, "Computational Mechanics: Pattern and Prediction, Structure and Simplicity" (2001)

---

## The Sections

**Crutchfield — Physics of Information and Computation** — Overview of the research program: how physical systems process information, and how to measure it.

**Epsilon Machines and Causal States** — The minimal sufficient models of stochastic processes. The simplest representations that capture all predictive structure in a system. A tool for measuring what is "really going on" in a complex process.

**Structural Complexity and Emergence** — How to distinguish genuine complexity from mere randomness. What it means for structure to *emerge* in a physical system. The hierarchy from order through complexity to chaos.
